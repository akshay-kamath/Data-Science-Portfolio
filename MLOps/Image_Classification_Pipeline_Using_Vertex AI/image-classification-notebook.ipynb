{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c92ee326-bbbc-4f2d-a178-73c170123a89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! mkdir ImageClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d89a1f09-8bc3-4bf8-9b89-7b9322ad7a93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Vertex AI Workbench Notebook product has specific requirements\n",
    "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\") and not os.getenv(\"VIRTUAL_ENV\")\n",
    "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
    "    \"/opt/deeplearning/metadata/env_version\"\n",
    ")\n",
    "\n",
    "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_WORKBENCH_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\"\n",
    "\n",
    "! pip3 install --upgrade --quiet {USER_FLAG} google-cloud-aiplatform kfp google-cloud-pipeline-components==1.0.40 google-cloud-storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20c376c2-6dd1-495e-a150-f35f6eddb960",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f04a4c6-411d-4675-a323-24f7df586dc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID:  qwiklabs-gcp-00-38ed10bd49be\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "PROJECT_ID = \"\"\n",
    "\n",
    "# Get your Google Cloud project ID from gcloud\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID: \", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "939a52dc-b15c-4a5a-ac89-d639d39200a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! mkdir pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a28538-1356-4468-902a-7e2e239c4d03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION=\"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cfb2e5f-33f4-4fc6-8911-e326189fd0dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-central1\n",
      "qwiklabs-gcp-00-38ed10bd49be-bucket\n",
      "qwiklabs-gcp-00-38ed10bd49be\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "BUCKET=PROJECT_ID + \"-bucket\"\n",
    "\n",
    "# set environment variable for reference later.\n",
    "os.environ['REGION']=REGION\n",
    "print(os.getenv('REGION'))\n",
    "\n",
    "os.environ['BUCKET']=BUCKET\n",
    "print(os.getenv('BUCKET'))\n",
    "\n",
    "os.environ['PROJECT_ID']=PROJECT_ID\n",
    "print(os.getenv('PROJECT_ID'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f784986a-3137-4bdd-b144-3c7c6a91378b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "google-cloud-aiplatform\n",
    "kfp\n",
    "google-cloud-pipeline-components==1.0.40\n",
    "google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e144809-dc7c-42a8-884d-ee2bb4568033",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing pipelines/train_pipeline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pipelines/train_pipeline.py\n",
    "\n",
    "import os\n",
    "\n",
    "import kfp\n",
    "import time\n",
    "from kfp.v2 import compiler, dsl\n",
    "from kfp.v2.dsl import component, pipeline, Artifact, ClassificationMetrics, Input, Output, Model, Metrics, Dataset\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from typing import NamedTuple, Dict\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "#Main pipeline class\n",
    "class pipeline_controller():\n",
    "    def __init__(self, template_path, display_name, pipeline_root, project_id, region):\n",
    "        self.template_path = template_path\n",
    "        self.display_name = display_name\n",
    "        self.pipeline_root = pipeline_root\n",
    "        self.project_id = project_id\n",
    "        self.region = region\n",
    "    \n",
    "    def _build_compile_pipeline(self):\n",
    "        \"\"\"Method to build and compile pipeline\"\"\"\n",
    "        self.pipeline = self._get_pipeline(self.project_id, self.region)\n",
    "        compiler.Compiler().compile(\n",
    "            pipeline_func=self.pipeline, package_path=self.template_path\n",
    "        )\n",
    "        \n",
    "    def _submit_job(self):\n",
    "        \"\"\"Method to Submit ML Pipeline job\"\"\"\n",
    "        #Next, define the job:\n",
    "        ml_pipeline_job = aiplatform.PipelineJob(\n",
    "            display_name=self.display_name,\n",
    "            template_path=self.template_path,\n",
    "            pipeline_root=self.pipeline_root,\n",
    "            project=self.project_id,\n",
    "            location=self.region,\n",
    "            # parameter_values={\"project\": self.project_id, \"display_name\": self.display_name},\n",
    "            enable_caching=False\n",
    "        )\n",
    "\n",
    "        #And finally, run the job:\n",
    "        ml_pipeline_job.submit()\n",
    "    \n",
    "    def _get_pipeline(self, PROJECT_ID, REGION):\n",
    "        ## Light weight component to create an Image DS\n",
    "        @component(\n",
    "            base_image=\"python:3.9-slim\",\n",
    "            packages_to_install=[\"google-api-core==2.10.2\", \"google-cloud\", \"google-cloud-aiplatform\", \"typing\", \"kfp\"],\n",
    "        )\n",
    "        def create_ds(project: str, \n",
    "                      display_name: str, \n",
    "                      gcs_source: str, \n",
    "                      import_schema_uri: str, \n",
    "                      timeout: int, \n",
    "                      dataset: Output[Dataset]):\n",
    "\n",
    "            from google.cloud import aiplatform\n",
    "            from google.cloud.aiplatform import datasets\n",
    "            from kfp.v2.dsl import Dataset\n",
    "\n",
    "            aiplatform.init(project=project)\n",
    "\n",
    "            obj_dataset = datasets.ImageDataset.create(\n",
    "                display_name=display_name,\n",
    "                gcs_source=gcs_source,\n",
    "                import_schema_uri=import_schema_uri,\n",
    "                create_request_timeout=timeout,\n",
    "            )\n",
    "\n",
    "            obj_dataset.wait()\n",
    "\n",
    "            dataset.uri = obj_dataset.gca_resource.name\n",
    "            dataset.metadata = {\n",
    "                'resourceName': obj_dataset.gca_resource.name\n",
    "            }\n",
    "        \n",
    "        \"\"\"Main method to Create pipeline\"\"\"\n",
    "        @pipeline(name=self.display_name,\n",
    "                    pipeline_root=self.pipeline_root)\n",
    "        def pipeline_fn(\n",
    "            project: str = PROJECT_ID, \n",
    "            region: str = REGION\n",
    "        ):\n",
    "            \n",
    "            from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "            from google_cloud_pipeline_components.v1.endpoint import (EndpointCreateOp, ModelDeployOp)\n",
    "            import google.cloud.aiplatform as aip\n",
    "\n",
    "            ds_op = create_ds(\n",
    "                project=project,\n",
    "                display_name=\"flowers\",\n",
    "                gcs_source=\"gs://cloud-samples-data/vision/automl_classification/flowers/all_data_v2.csv\",\n",
    "                import_schema_uri=aip.schema.dataset.ioformat.image.single_label_classification,\n",
    "                timeout=3600\n",
    "            )\n",
    "\n",
    "            training_job_run_op = gcc_aip.AutoMLImageTrainingJobRunOp(\n",
    "                project=project,\n",
    "                location=region,\n",
    "                display_name=\"train-automl-flowers\",\n",
    "                prediction_type=\"classification\",\n",
    "                model_type=\"CLOUD\",\n",
    "                dataset=ds_op.outputs[\"dataset\"].ignore_type(),\n",
    "                model_display_name=\"train-automl-flowers\",\n",
    "                training_fraction_split=0.6,\n",
    "                validation_fraction_split=0.2,\n",
    "                test_fraction_split=0.2,\n",
    "                budget_milli_node_hours=8000,\n",
    "            )\n",
    "\n",
    "            endpoint_op = EndpointCreateOp(\n",
    "                project=project,\n",
    "                location=region,\n",
    "                display_name=\"train-automl-flowers\",\n",
    "            )\n",
    "\n",
    "            ModelDeployOp(\n",
    "                model=training_job_run_op.outputs[\"model\"],\n",
    "                endpoint=endpoint_op.outputs[\"endpoint\"],\n",
    "                automatic_resources_min_replica_count=1,\n",
    "                automatic_resources_max_replica_count=1,\n",
    "            )\n",
    "\n",
    "        #Returns as the output of _get_pipeline()\n",
    "        return pipeline_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c71f7582-c3dd-4849-af18-b64f289d48a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGION: us-central1\n",
      "PROJECT_ID: qwiklabs-gcp-00-38ed10bd49be\n",
      "BUCKET: qwiklabs-gcp-00-38ed10bd49be-bucket\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "BUCKET=PROJECT_ID + \"-bucket\"\n",
    "\n",
    "# set environment variable for reference later.\n",
    "os.environ['REGION']=REGION\n",
    "print(\"REGION: \" + os.getenv('REGION'))\n",
    "\n",
    "os.environ['PROJECT_ID']=PROJECT_ID\n",
    "print(\"PROJECT_ID: \" + os.getenv('PROJECT_ID'))\n",
    "\n",
    "os.environ['BUCKET']=BUCKET\n",
    "print(\"BUCKET: \" + os.getenv('BUCKET'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "452b7be0-8b1a-4bf7-8431-6abd9bd22482",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing build_and_deploy.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile build_and_deploy.py\n",
    "\n",
    "###Code to Build and Deploy the full pipeline\n",
    "###This will be used in Cloud Builder\n",
    "\n",
    "#Initialize pipeline object\n",
    "from pipelines.train_pipeline import pipeline_controller\n",
    "import time\n",
    "import os\n",
    "\n",
    "REGION=\"us-central1\"\n",
    "PROJECT_ID=\"qwiklabs-gcp-00-38ed10bd49be\" \n",
    "BUCKET=f\"{PROJECT_ID}-bucket\"\n",
    "\n",
    "PIPELINE_ROOT = f\"gs://{BUCKET}/pipeline_root/\"\n",
    "DISPLAY_NAME = 'vertex-customml-pipeline{}'.format(str(int(time.time())))\n",
    "\n",
    "print(\"Building pipeline {}\".format(DISPLAY_NAME))\n",
    "\n",
    "pipe = pipeline_controller(template_path=\"pipeline.json\",\n",
    "                           display_name=\"vertex-automlimage-classif\", \n",
    "                           pipeline_root=PIPELINE_ROOT,\n",
    "                           project_id=PROJECT_ID,\n",
    "                           region=REGION)\n",
    "\n",
    "#Build and Compile pipeline\n",
    "pipe._build_compile_pipeline()\n",
    "\n",
    "##Submit Job\n",
    "pipe._submit_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7634c2b9-ef2e-4f30-9b84-04914efbb516",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building pipeline vertex-customml-pipeline1742223435\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/kfp/v2/compiler/compiler.py:1290: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  warnings.warn(\n",
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/26289415277/locations/us-central1/pipelineJobs/vertex-automlimage-classif-20250317145715\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/26289415277/locations/us-central1/pipelineJobs/vertex-automlimage-classif-20250317145715')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/vertex-automlimage-classif-20250317145715?project=26289415277\n"
     ]
    }
   ],
   "source": [
    "!python -m build_and_deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd0dc884-3870-48f4-89cf-5f411c235406",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "# Download dependencies to /root/.local.\n",
    "FROM python:3.7-slim AS builder\n",
    "COPY requirements.txt .\n",
    "\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "COPY . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "278f9ade-bea9-48fb-bf1f-688de3bca3b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create request issued for: [vertex-gar]\n",
      "Waiting for operation [projects/qwiklabs-gcp-00-38ed10bd49be/locations/us-centr\n",
      "al1/operations/68dc8cf1-4d73-4eaa-9c8d-31e69b345e60] to complete...done.       \n",
      "Created repository [vertex-gar].\n"
     ]
    }
   ],
   "source": [
    "!gcloud artifacts repositories create vertex-gar \\\n",
    "    --project=$PROJECT_ID \\\n",
    "    --repository-format=Docker \\\n",
    "    --location=$REGION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f60cec43-49e6-4855-88a7-aaf75c85d1a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cloudbuild.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile cloudbuild.yaml\n",
    "\n",
    "# Create config file and build a new image tagged with the given commit hash.\n",
    "\n",
    "steps:\n",
    "##Step 1 -> Build main image from Dockerfile\n",
    "- name: 'gcr.io/cloud-builders/docker'\n",
    "  id: 'build_image'\n",
    "  args: [\n",
    "    'build', '-t', '{REGION}-docker.pkg.dev/{PROJECT_ID}/vertex-gar/latest:latest',\n",
    "    '-f', 'Dockerfile', '.',\n",
    "  ]\n",
    "\n",
    "##Step 2 -> Deploy Docker image to Artifact Repository\n",
    "- name: 'gcr.io/cloud-builders/docker'\n",
    "  id: 'push_image'\n",
    "  waitFor:\n",
    "    - 'build_image'\n",
    "  args: [\n",
    "    'push', '{REGION}-docker.pkg.dev/{PROJECT_ID}/vertex-gar/latest:latest'\n",
    "  ]\n",
    "\n",
    "##Step 3 -> Deploy pipeline to Vertex AI( using above built image )\n",
    "- name: '{REGION}-docker.pkg.dev/{PROJECT_ID}/vertex-gar/latest:latest'\n",
    "  id: 'deploy_pipelines'\n",
    "  waitFor:\n",
    "    - 'push_image'\n",
    "  entrypoint: /bin/bash\n",
    "  args:\n",
    "    - -c\n",
    "    - |\n",
    "      python -m build_and_deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd1b82a4-cc76-4061-89e0-e647997acb9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Run the following command to replace {PROJECT_ID}/{REGION} with project id/region\n",
    "cmd_str_proj = 's/[{]PROJECT_ID[}]/' + PROJECT_ID + '/g'\n",
    "cmd_str_region = 's/[{]REGION[}]/' + REGION + '/g'\n",
    "! sed -i $cmd_str_proj cloudbuild.yaml\n",
    "! sed -i $cmd_str_region cloudbuild.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b08866d-de5c-4b83-bd2c-f06a6e37ef1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary archive of 5908 file(s) totalling 160.6 MiB before compression.\n",
      "Uploading tarball of [.] to [gs://qwiklabs-gcp-00-38ed10bd49be_cloudbuild/source/1742224466.932253-d452608730804ce78704f25ea6c5fd7a.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/qwiklabs-gcp-00-38ed10bd49be/locations/global/builds/3a9c0177-c8aa-4f89-9130-d46d0c0276ce].\n",
      "Logs are available at [ https://console.cloud.google.com/cloud-build/builds/3a9c0177-c8aa-4f89-9130-d46d0c0276ce?project=26289415277 ].\n",
      "Waiting for build to complete. Polling interval: 1 second(s).\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"3a9c0177-c8aa-4f89-9130-d46d0c0276ce\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://qwiklabs-gcp-00-38ed10bd49be_cloudbuild/source/1742224466.932253-d452608730804ce78704f25ea6c5fd7a.tgz#1742224504520270\n",
      "Copying gs://qwiklabs-gcp-00-38ed10bd49be_cloudbuild/source/1742224466.932253-d452608730804ce78704f25ea6c5fd7a.tgz#1742224504520270...\n",
      "/ [1 files][ 29.1 MiB/ 29.1 MiB]                                                \n",
      "Operation completed over 1 objects/29.1 MiB.\n",
      "BUILD\n",
      "Starting Step #0 - \"build_image\"\n",
      "Step #0 - \"build_image\": Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Step #0 - \"build_image\": Sending build context to Docker daemon  174.7MB\n",
      "Step #0 - \"build_image\": Step 1/4 : FROM python:3.7-slim AS builder\n",
      "Step #0 - \"build_image\": 3.7-slim: Pulling from library/python\n",
      "Step #0 - \"build_image\": a803e7c4b030: Pulling fs layer\n",
      "Step #0 - \"build_image\": bf3336e84c8e: Pulling fs layer\n",
      "Step #0 - \"build_image\": 8973eb85275f: Pulling fs layer\n",
      "Step #0 - \"build_image\": f9afc3cc0135: Pulling fs layer\n",
      "Step #0 - \"build_image\": 39312d8b4ab7: Pulling fs layer\n",
      "Step #0 - \"build_image\": 39312d8b4ab7: Waiting\n",
      "Step #0 - \"build_image\": f9afc3cc0135: Waiting\n",
      "Step #0 - \"build_image\": 8973eb85275f: Verifying Checksum\n",
      "Step #0 - \"build_image\": 8973eb85275f: Download complete\n",
      "Step #0 - \"build_image\": bf3336e84c8e: Verifying Checksum\n",
      "Step #0 - \"build_image\": bf3336e84c8e: Download complete\n",
      "Step #0 - \"build_image\": a803e7c4b030: Verifying Checksum\n",
      "Step #0 - \"build_image\": a803e7c4b030: Download complete\n",
      "Step #0 - \"build_image\": f9afc3cc0135: Verifying Checksum\n",
      "Step #0 - \"build_image\": f9afc3cc0135: Download complete\n",
      "Step #0 - \"build_image\": 39312d8b4ab7: Verifying Checksum\n",
      "Step #0 - \"build_image\": 39312d8b4ab7: Download complete\n",
      "Step #0 - \"build_image\": a803e7c4b030: Pull complete\n",
      "Step #0 - \"build_image\": bf3336e84c8e: Pull complete\n",
      "Step #0 - \"build_image\": 8973eb85275f: Pull complete\n",
      "Step #0 - \"build_image\": f9afc3cc0135: Pull complete\n",
      "Step #0 - \"build_image\": 39312d8b4ab7: Pull complete\n",
      "Step #0 - \"build_image\": Digest: sha256:b53f496ca43e5af6994f8e316cf03af31050bf7944e0e4a308ad86c001cf028b\n",
      "Step #0 - \"build_image\": Status: Downloaded newer image for python:3.7-slim\n",
      "Step #0 - \"build_image\":  ---> a255ffcb469f\n",
      "Step #0 - \"build_image\": Step 2/4 : COPY requirements.txt .\n",
      "Step #0 - \"build_image\":  ---> f9558c69c20b\n",
      "Step #0 - \"build_image\": Step 3/4 : RUN pip install -r requirements.txt\n",
      "Step #0 - \"build_image\":  ---> Running in 91d3bc143f13\n",
      "Step #0 - \"build_image\": Collecting google-cloud-aiplatform\n",
      "Step #0 - \"build_image\":   Downloading google_cloud_aiplatform-1.34.0-py2.py3-none-any.whl (3.1 MB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 36.5 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting kfp\n",
      "Step #0 - \"build_image\":   Downloading kfp-2.7.0.tar.gz (441 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 441.8/441.8 kB 44.2 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\":   Preparing metadata (setup.py): started\n",
      "Step #0 - \"build_image\":   Preparing metadata (setup.py): finished with status 'done'\n",
      "Step #0 - \"build_image\": Collecting google-cloud-pipeline-components==1.0.40\n",
      "Step #0 - \"build_image\":   Downloading google_cloud_pipeline_components-1.0.40-py3-none-any.whl (1.0 MB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 58.1 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting google-cloud-storage\n",
      "Step #0 - \"build_image\":   Downloading google_cloud_storage-3.1.0-py2.py3-none-any.whl (174 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 174.9/174.9 kB 28.8 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.31.5\n",
      "Step #0 - \"build_image\":   Downloading google_api_core-2.24.2-py3-none-any.whl (160 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 160.1/160.1 kB 26.1 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting grpcio-status<=1.47.0\n",
      "Step #0 - \"build_image\":   Downloading grpcio_status-1.47.0-py3-none-any.whl (10.0 kB)\n",
      "Step #0 - \"build_image\": Collecting protobuf<4.0.0dev,>=3.19.0\n",
      "Step #0 - \"build_image\":   Downloading protobuf-3.20.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 61.5 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting google-cloud-notebooks>=0.4.0\n",
      "Step #0 - \"build_image\":   Downloading google_cloud_notebooks-1.13.2-py3-none-any.whl (301 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 301.4/301.4 kB 41.3 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting google-cloud-storage\n",
      "Step #0 - \"build_image\":   Downloading google_cloud_storage-2.19.0-py2.py3-none-any.whl (131 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 131.8/131.8 kB 21.6 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting googleapis-common-protos<2.0dev,>=1.56.2\n",
      "Step #0 - \"build_image\":   Downloading googleapis_common_protos-1.69.2-py3-none-any.whl (293 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 293.2/293.2 kB 38.6 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting kfp\n",
      "Step #0 - \"build_image\":   Downloading kfp-1.8.22.tar.gz (304 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 304.9/304.9 kB 40.5 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\":   Preparing metadata (setup.py): started\n",
      "Step #0 - \"build_image\":   Preparing metadata (setup.py): finished with status 'done'\n",
      "Step #0 - \"build_image\": Collecting proto-plus<2.0.0dev,>=1.22.0\n",
      "Step #0 - \"build_image\":   Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.2/50.2 kB 8.7 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3\n",
      "Step #0 - \"build_image\":   Downloading google_cloud_resource_manager-1.14.2-py3-none-any.whl (394 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 394.3/394.3 kB 43.8 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting packaging>=14.3\n",
      "Step #0 - \"build_image\":   Downloading packaging-24.0-py3-none-any.whl (53 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.5/53.5 kB 9.7 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting shapely<2.0.0\n",
      "Step #0 - \"build_image\":   Downloading Shapely-1.8.5.post1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.0 MB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 72.2 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting google-cloud-bigquery<4.0.0dev,>=1.15.0\n",
      "Step #0 - \"build_image\":   Downloading google_cloud_bigquery-3.30.0-py2.py3-none-any.whl (247 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 247.9/247.9 kB 35.5 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting absl-py<2,>=0.9\n",
      "Step #0 - \"build_image\":   Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.5/126.5 kB 20.9 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting PyYAML<7,>=5.3\n",
      "Step #0 - \"build_image\":   Downloading PyYAML-6.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (670 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 670.1/670.1 kB 51.0 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting kubernetes<26,>=8.0.0\n",
      "Step #0 - \"build_image\":   Downloading kubernetes-25.3.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 65.6 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting google-api-python-client<2,>=1.7.8\n",
      "Step #0 - \"build_image\":   Downloading google_api_python_client-1.12.11-py2.py3-none-any.whl (62 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.1/62.1 kB 11.4 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting google-auth<3,>=1.6.1\n",
      "Step #0 - \"build_image\":   Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 210.8/210.8 kB 29.0 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting requests-toolbelt<1,>=0.8.0\n",
      "Step #0 - \"build_image\":   Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.5/54.5 kB 9.2 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting cloudpickle<3,>=2.0.0\n",
      "Step #0 - \"build_image\":   Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Step #0 - \"build_image\": Collecting kfp-server-api<2.0.0,>=1.1.2\n",
      "Step #0 - \"build_image\":   Downloading kfp-server-api-1.8.5.tar.gz (58 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.1/58.1 kB 10.7 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\":   Preparing metadata (setup.py): started\n",
      "Step #0 - \"build_image\":   Preparing metadata (setup.py): finished with status 'done'\n",
      "Step #0 - \"build_image\": Collecting jsonschema<5,>=3.0.1\n",
      "Step #0 - \"build_image\":   Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 90.4/90.4 kB 15.4 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting tabulate<1,>=0.8.6\n",
      "Step #0 - \"build_image\":   Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Step #0 - \"build_image\": Collecting click<9,>=7.1.2\n",
      "Step #0 - \"build_image\":   Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 98.2/98.2 kB 16.3 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting Deprecated<2,>=1.2.7\n",
      "Step #0 - \"build_image\":   Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Step #0 - \"build_image\": Collecting strip-hints<1,>=0.1.8\n",
      "Step #0 - \"build_image\":   Downloading strip_hints-0.1.13-py3-none-any.whl (23 kB)\n",
      "Step #0 - \"build_image\": Collecting docstring-parser<1,>=0.7.3\n",
      "Step #0 - \"build_image\":   Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Step #0 - \"build_image\": Collecting kfp-pipeline-spec<0.2.0,>=0.1.16\n",
      "Step #0 - \"build_image\":   Downloading kfp_pipeline_spec-0.1.16-py3-none-any.whl (19 kB)\n",
      "Step #0 - \"build_image\": Collecting fire<1,>=0.3.1\n",
      "Step #0 - \"build_image\":   Downloading fire-0.7.0.tar.gz (87 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 87.2/87.2 kB 15.2 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\":   Preparing metadata (setup.py): started\n",
      "Step #0 - \"build_image\":   Preparing metadata (setup.py): finished with status 'done'\n",
      "Step #0 - \"build_image\": Collecting uritemplate<4,>=3.0.1\n",
      "Step #0 - \"build_image\":   Downloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
      "Step #0 - \"build_image\": Collecting urllib3<2\n",
      "Step #0 - \"build_image\":   Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 144.2/144.2 kB 24.9 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting pydantic<2,>=1.8.2\n",
      "Step #0 - \"build_image\":   Downloading pydantic-1.10.21-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 78.8 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting typer<1.0,>=0.3.2\n",
      "Step #0 - \"build_image\":   Downloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 45.1/45.1 kB 8.4 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting typing-extensions<5,>=3.7.4\n",
      "Step #0 - \"build_image\":   Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Step #0 - \"build_image\": Collecting google-resumable-media>=2.7.2\n",
      "Step #0 - \"build_image\":   Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.3/81.3 kB 15.4 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting requests<3.0.0dev,>=2.18.0\n",
      "Step #0 - \"build_image\":   Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.6/62.6 kB 12.2 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting google-cloud-core<3.0dev,>=2.3.0\n",
      "Step #0 - \"build_image\":   Downloading google_cloud_core-2.4.3-py2.py3-none-any.whl (29 kB)\n",
      "Step #0 - \"build_image\": Collecting google-crc32c<2.0dev,>=1.0\n",
      "Step #0 - \"build_image\":   Downloading google_crc32c-1.5.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
      "Step #0 - \"build_image\": Collecting importlib-metadata\n",
      "Step #0 - \"build_image\":   Downloading importlib_metadata-6.7.0-py3-none-any.whl (22 kB)\n",
      "Step #0 - \"build_image\": Collecting wrapt<2,>=1.10\n",
      "Step #0 - \"build_image\":   Downloading wrapt-1.16.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.5/77.5 kB 14.8 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting termcolor\n",
      "Step #0 - \"build_image\":   Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Step #0 - \"build_image\": Collecting grpcio<2.0dev,>=1.33.2\n",
      "Step #0 - \"build_image\":   Downloading grpcio-1.62.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.6/5.6 MB 76.7 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting httplib2<1dev,>=0.15.0\n",
      "Step #0 - \"build_image\":   Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 96.9/96.9 kB 16.4 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting six<2dev,>=1.13.0\n",
      "Step #0 - \"build_image\":   Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Step #0 - \"build_image\": Collecting google-auth-httplib2>=0.0.3\n",
      "Step #0 - \"build_image\":   Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Step #0 - \"build_image\": Collecting pyasn1-modules>=0.2.1\n",
      "Step #0 - \"build_image\":   Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.3/181.3 kB 27.0 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting rsa<5,>=3.1.4\n",
      "Step #0 - \"build_image\":   Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Step #0 - \"build_image\": Collecting cachetools<6.0,>=2.0.0\n",
      "Step #0 - \"build_image\":   Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Step #0 - \"build_image\": Collecting python-dateutil<3.0dev,>=2.7.3\n",
      "Step #0 - \"build_image\":   Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 229.9/229.9 kB 31.5 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting grpc-google-iam-v1<1.0.0,>=0.14.0\n",
      "Step #0 - \"build_image\":   Downloading grpc_google_iam_v1-0.14.2-py3-none-any.whl (19 kB)\n",
      "Step #0 - \"build_image\": Collecting pkgutil-resolve-name>=1.3.10\n",
      "Step #0 - \"build_image\":   Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n",
      "Step #0 - \"build_image\": Collecting importlib-resources>=1.4.0\n",
      "Step #0 - \"build_image\":   Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
      "Step #0 - \"build_image\": Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n",
      "Step #0 - \"build_image\":   Downloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 10.9 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting attrs>=17.4.0\n",
      "Step #0 - \"build_image\":   Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.0/63.0 kB 11.1 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting certifi\n",
      "Step #0 - \"build_image\":   Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 166.4/166.4 kB 26.1 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.7/site-packages (from kubernetes<26,>=8.0.0->kfp->-r requirements.txt (line 2)) (57.5.0)\n",
      "Step #0 - \"build_image\": Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0\n",
      "Step #0 - \"build_image\":   Downloading websocket_client-1.6.1-py3-none-any.whl (56 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.9/56.9 kB 10.9 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting requests-oauthlib\n",
      "Step #0 - \"build_image\":   Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Step #0 - \"build_image\": Collecting idna<4,>=2.5\n",
      "Step #0 - \"build_image\":   Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 70.4/70.4 kB 13.2 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting charset-normalizer<4,>=2\n",
      "Step #0 - \"build_image\":   Downloading charset_normalizer-3.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 138.6/138.6 kB 24.2 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Requirement already satisfied: wheel in /usr/local/lib/python3.7/site-packages (from strip-hints<1,>=0.1.8->kfp->-r requirements.txt (line 2)) (0.41.2)\n",
      "Step #0 - \"build_image\": Collecting shellingham>=1.3.0\n",
      "Step #0 - \"build_image\":   Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Step #0 - \"build_image\": Collecting rich>=10.11.0\n",
      "Step #0 - \"build_image\":   Downloading rich-13.8.1-py3-none-any.whl (241 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 241.6/241.6 kB 31.6 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2\n",
      "Step #0 - \"build_image\":   Downloading pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 104.1/104.1 kB 19.4 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting zipp>=0.5\n",
      "Step #0 - \"build_image\":   Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
      "Step #0 - \"build_image\": Collecting pyasn1<0.6.0,>=0.4.6\n",
      "Step #0 - \"build_image\":   Downloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.9/84.9 kB 14.8 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting pygments<3.0.0,>=2.13.0\n",
      "Step #0 - \"build_image\":   Downloading pygments-2.17.2-py3-none-any.whl (1.2 MB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 53.5 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting markdown-it-py>=2.2.0\n",
      "Step #0 - \"build_image\":   Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.5/84.5 kB 15.7 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting oauthlib>=3.0.0\n",
      "Step #0 - \"build_image\":   Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Step #0 - \"build_image\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 24.3 MB/s eta 0:00:00\n",
      "Step #0 - \"build_image\": Collecting mdurl~=0.1\n",
      "Step #0 - \"build_image\":   Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Step #0 - \"build_image\": Building wheels for collected packages: kfp, fire, kfp-server-api\n",
      "Step #0 - \"build_image\":   Building wheel for kfp (setup.py): started\n",
      "Step #0 - \"build_image\":   Building wheel for kfp (setup.py): finished with status 'done'\n",
      "Step #0 - \"build_image\":   Created wheel for kfp: filename=kfp-1.8.22-py3-none-any.whl size=426989 sha256=c6a5ff78e0c863dec6d73072e2a9fad5c4bdf48e048f28d2f395c8b6c5b6d5f3\n",
      "Step #0 - \"build_image\":   Stored in directory: /root/.cache/pip/wheels/f1/ea/2f/99e16eb441be7831b69cb568df54a0dd04ab31cb758bfc6819\n",
      "Step #0 - \"build_image\":   Building wheel for fire (setup.py): started\n",
      "Step #0 - \"build_image\":   Building wheel for fire (setup.py): finished with status 'done'\n",
      "Step #0 - \"build_image\":   Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114259 sha256=36fb23fb101705abf67a4c72fefe2a1f24cc324469277451ff76343a5178f08e\n",
      "Step #0 - \"build_image\":   Stored in directory: /root/.cache/pip/wheels/e2/5a/25/38c86410f5a3b45d74468fd36ff0e1eb9a0c78edbb00169580\n",
      "Step #0 - \"build_image\":   Building wheel for kfp-server-api (setup.py): started\n",
      "Step #0 - \"build_image\":   Building wheel for kfp-server-api (setup.py): finished with status 'done'\n",
      "Step #0 - \"build_image\":   Created wheel for kfp-server-api: filename=kfp_server_api-1.8.5-py3-none-any.whl size=99710 sha256=b6dee37d684d73c6d1364342cd476ba571a7b499c41a036fd7ed4abf93e0793a\n",
      "Step #0 - \"build_image\":   Stored in directory: /root/.cache/pip/wheels/77/0e/7b/ed385d69453b7b754834c01d83fa9f5708ba66b4f6ed5d6a35\n",
      "Step #0 - \"build_image\": Successfully built kfp fire kfp-server-api\n",
      "Step #0 - \"build_image\": Installing collected packages: zipp, wrapt, websocket-client, urllib3, uritemplate, typing-extensions, termcolor, tabulate, strip-hints, six, shellingham, shapely, PyYAML, pyrsistent, pyparsing, pygments, pyasn1, protobuf, pkgutil-resolve-name, packaging, oauthlib, mdurl, idna, grpcio, google-crc32c, docstring-parser, cloudpickle, charset-normalizer, certifi, cachetools, absl-py, rsa, requests, python-dateutil, pydantic, pyasn1-modules, proto-plus, markdown-it-py, kfp-pipeline-spec, importlib-resources, importlib-metadata, httplib2, googleapis-common-protos, google-resumable-media, fire, Deprecated, rich, requests-toolbelt, requests-oauthlib, kfp-server-api, grpcio-status, google-auth, click, attrs, typer, kubernetes, jsonschema, grpc-google-iam-v1, google-auth-httplib2, google-api-core, google-cloud-core, google-api-python-client, google-cloud-storage, google-cloud-resource-manager, google-cloud-notebooks, google-cloud-bigquery, kfp, google-cloud-aiplatform, google-cloud-pipeline-components\n",
      "Step #0 - \"build_image\": Successfully installed Deprecated-1.2.18 PyYAML-6.0.1 absl-py-1.4.0 attrs-24.2.0 cachetools-5.5.2 certifi-2025.1.31 charset-normalizer-3.4.1 click-8.1.8 cloudpickle-2.2.1 docstring-parser-0.16 fire-0.7.0 google-api-core-2.24.2 google-api-python-client-1.12.11 google-auth-2.38.0 google-auth-httplib2-0.2.0 google-cloud-aiplatform-1.34.0 google-cloud-bigquery-3.30.0 google-cloud-core-2.4.3 google-cloud-notebooks-1.13.2 google-cloud-pipeline-components-1.0.40 google-cloud-resource-manager-1.14.2 google-cloud-storage-2.19.0 google-crc32c-1.5.0 google-resumable-media-2.7.2 googleapis-common-protos-1.69.2 grpc-google-iam-v1-0.14.2 grpcio-1.62.3 grpcio-status-1.47.0 httplib2-0.22.0 idna-3.10 importlib-metadata-6.7.0 importlib-resources-5.12.0 jsonschema-4.17.3 kfp-1.8.22 kfp-pipeline-spec-0.1.16 kfp-server-api-1.8.5 kubernetes-25.3.0 markdown-it-py-2.2.0 mdurl-0.1.2 oauthlib-3.2.2 packaging-24.0 pkgutil-resolve-name-1.3.10 proto-plus-1.26.1 protobuf-3.20.3 pyasn1-0.5.1 pyasn1-modules-0.3.0 pydantic-1.10.21 pygments-2.17.2 pyparsing-3.1.4 pyrsistent-0.19.3 python-dateutil-2.9.0.post0 requests-2.31.0 requests-oauthlib-2.0.0 requests-toolbelt-0.10.1 rich-13.8.1 rsa-4.9 shapely-1.8.5.post1 shellingham-1.5.4 six-1.17.0 strip-hints-0.1.13 tabulate-0.9.0 termcolor-2.3.0 typer-0.15.2 typing-extensions-4.7.1 uritemplate-3.0.1 urllib3-1.26.20 websocket-client-1.6.1 wrapt-1.16.0 zipp-3.15.0\n",
      "Step #0 - \"build_image\": \u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "Step #0 - \"build_image\": \u001b[0m\u001b[91m\n",
      "Step #0 - \"build_image\": [notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "Step #0 - \"build_image\": [notice] To update, run: pip install --upgrade pip\n",
      "Step #0 - \"build_image\": \u001b[0mRemoving intermediate container 91d3bc143f13\n",
      "Step #0 - \"build_image\":  ---> 10671165df53\n",
      "Step #0 - \"build_image\": Step 4/4 : COPY . .\n",
      "Step #0 - \"build_image\":  ---> c3adf8f17332\n",
      "Step #0 - \"build_image\": Successfully built c3adf8f17332\n",
      "Step #0 - \"build_image\": Successfully tagged us-central1-docker.pkg.dev/qwiklabs-gcp-00-38ed10bd49be/vertex-gar/latest:latest\n",
      "Finished Step #0 - \"build_image\"\n",
      "Starting Step #1 - \"push_image\"\n",
      "Step #1 - \"push_image\": Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Step #1 - \"push_image\": The push refers to repository [us-central1-docker.pkg.dev/qwiklabs-gcp-00-38ed10bd49be/vertex-gar/latest]\n",
      "Step #1 - \"push_image\": 4dc7b499a89a: Preparing\n",
      "Step #1 - \"push_image\": b0282a35bd13: Preparing\n",
      "Step #1 - \"push_image\": d063357bb7b6: Preparing\n",
      "Step #1 - \"push_image\": b8594deafbe5: Preparing\n",
      "Step #1 - \"push_image\": 8a55150afecc: Preparing\n",
      "Step #1 - \"push_image\": ad34ffec41dd: Preparing\n",
      "Step #1 - \"push_image\": f19cb1e4112d: Preparing\n",
      "Step #1 - \"push_image\": d310e774110a: Preparing\n",
      "Step #1 - \"push_image\": ad34ffec41dd: Waiting\n",
      "Step #1 - \"push_image\": f19cb1e4112d: Waiting\n",
      "Step #1 - \"push_image\": d310e774110a: Waiting\n",
      "Step #1 - \"push_image\": d063357bb7b6: Pushed\n",
      "Step #1 - \"push_image\": 8a55150afecc: Pushed\n",
      "Step #1 - \"push_image\": f19cb1e4112d: Pushed\n",
      "Step #1 - \"push_image\": b8594deafbe5: Pushed\n",
      "Step #1 - \"push_image\": ad34ffec41dd: Pushed\n",
      "Step #1 - \"push_image\": d310e774110a: Pushed\n",
      "Step #1 - \"push_image\": 4dc7b499a89a: Pushed\n",
      "Step #1 - \"push_image\": b0282a35bd13: Pushed\n",
      "Step #1 - \"push_image\": latest: digest: sha256:99a515b6f5b9bc6f5e2242b4cde10312093b5202749783298581502622d24986 size: 2001\n",
      "Finished Step #1 - \"push_image\"\n",
      "Starting Step #2 - \"deploy_pipelines\"\n",
      "Step #2 - \"deploy_pipelines\": Already have image (with digest): us-central1-docker.pkg.dev/qwiklabs-gcp-00-38ed10bd49be/vertex-gar/latest:latest\n",
      "Step #2 - \"deploy_pipelines\": Building pipeline vertex-customml-pipeline1742224594\n",
      "Step #2 - \"deploy_pipelines\": Creating PipelineJob\n",
      "Step #2 - \"deploy_pipelines\": PipelineJob created. Resource name: projects/26289415277/locations/us-central1/pipelineJobs/vertex-automlimage-classif-20250317151634\n",
      "Step #2 - \"deploy_pipelines\": To use this PipelineJob in another session:\n",
      "Step #2 - \"deploy_pipelines\": pipeline_job = aiplatform.PipelineJob.get('projects/26289415277/locations/us-central1/pipelineJobs/vertex-automlimage-classif-20250317151634')\n",
      "Step #2 - \"deploy_pipelines\": View Pipeline Job:\n",
      "Step #2 - \"deploy_pipelines\": https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/vertex-automlimage-classif-20250317151634?project=26289415277\n",
      "Step #2 - \"deploy_pipelines\": /usr/local/lib/python3.7/site-packages/kfp/v2/compiler/compiler.py:1293: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "Step #2 - \"deploy_pipelines\":   category=FutureWarning,\n",
      "Finished Step #2 - \"deploy_pipelines\"\n",
      "PUSH\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                                      IMAGES  STATUS\n",
      "3a9c0177-c8aa-4f89-9130-d46d0c0276ce  2025-03-17T15:15:04+00:00  1M28S     gs://qwiklabs-gcp-00-38ed10bd49be_cloudbuild/source/1742224466.932253-d452608730804ce78704f25ea6c5fd7a.tgz  -       SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit --config=cloudbuild.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3d6736-8f9c-4111-9f15-901b3e6a68ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-15.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-15:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
